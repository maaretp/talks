# AI-Driven Application Testing

*Length: 45 minutes* 

With machine learning, large language models and retrieval augmented generation, there's plenty of things AI out there. For 'acting humanly' framing to AI, any software doing things humans could do gets bundled in the new wave of AI-driven application testing. Armed with mindset of evaluation and amplifying fail signals, we are educated with great examples of the many ways these technologies fail. We have less education on the guardrails on how these technologies add to results of testing and productivity. We need the warnings to make sense if _we_ are ok with _all_ of this, yet the time to listen and deliver warnings is time away from figuring out the guardrails to succeed with this. Succeed with what is available to us all today, even if not yet perfectly packaged.

In this talk, we go through three demos, framed with a perspective of someone who cares about results of testing and value of testing perspective in software development. We have people around with these augmented intelligence solutions, and we need a conversation that is framed with the change of testing and curiosity, rather than fear. We need sociotechnical guardrails providing us useful solutions. Given there is a problem here, how do we work with AI so that we recognize and mitigate the problems? How do we move from value of fun to value at our work and discuss use of time in a frame of curiosity, building a future we can and want to be around? How you would use AI for it to be useful to you and your organization? 

Time used on something is time away from something else. You'll use time listening to this, and chances are you're able to navigate the waters of AI-driven application testing a little better, today.
